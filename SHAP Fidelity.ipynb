{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from xgboost import XGBClassifier\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 33)\n",
      "Index(['sex', 'age', 'studytime', 'failures', 'absences', 'activities', 'G1',\n",
      "       'Medu', 'Fedu'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('student-por.csv')\n",
    "print(data.shape)\n",
    "\n",
    "data['G2'] = round(data['G2']/2)\n",
    "y = np.where(data['G2']>5, 1, 0)\n",
    "\n",
    "data = data[['sex', 'age', 'studytime', 'failures', 'absences', 'activities', 'G1', 'Medu', 'Fedu']]\n",
    "originial_features = data.columns\n",
    "data['G1'] = round(data['G1']/2)\n",
    "sex = {'M': 0, 'F': 1}\n",
    "activities = {'no': 0, 'yes': 1}\n",
    "data = data.replace({'sex': sex})\n",
    "data = data.replace({'activities': activities})\n",
    "categorical_vars ={}\n",
    "X = data\n",
    "features = X.columns\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Telephone' 'Account Balance' 'Duration of Credit (month)'\n",
      " 'Credit Amount' 'Age (years)' 'Credit History' 'Guarantor'\n",
      " 'Credit Purpose_Car' 'Credit Purpose_Home Related' 'Credit Purpose_Other']\n"
     ]
    }
   ],
   "source": [
    "########################## GERMAN\n",
    "\n",
    "data = pd.read_csv('german_credit.csv')\n",
    "\n",
    "data =  data[['Purpose', 'Telephone', 'Account Balance', 'Duration of Credit (month)', 'Payment Status of Previous Credit',\n",
    "            'Credit Amount', 'Guarantors', 'Age (years)', 'Creditability']]\n",
    "#Purpose is a categorical variable, but some of its levels are merged\n",
    "data.loc[data.Purpose <= 1, 'Credit Purpose'] = 1\n",
    "data.loc[((data.Purpose>1) & (data.Purpose<=5)), 'Credit Purpose'] = 2\n",
    "data.loc[data.Purpose>5, 'Credit Purpose'] = 3\n",
    "\n",
    "data.loc[data['Payment Status of Previous Credit'] <= 1, 'Credit History'] = 1\n",
    "data.loc[data['Payment Status of Previous Credit'] > 1, 'Credit History'] = 2\n",
    "\n",
    "data.loc[data['Guarantors'] == 1, 'Guarantor'] = 1\n",
    "data.loc[data['Guarantors'] > 1, 'Guarantor'] = 2\n",
    "\n",
    "\n",
    "# making boolean series for a team name \n",
    "filter1 = (data[\"Credit History\"]== 1)\n",
    "filter2 = (data[\"Creditability\"] == 0)\n",
    "\n",
    "filter3 = (data[\"Credit History\"]== 1)\n",
    "filter4 = (data[\"Creditability\"] == 1)\n",
    "\n",
    "\n",
    "data['Weight'] = np.where((filter1 & filter2 | filter3 & filter4), .8, .1)\n",
    "stupid_dataset = data.sample(frac=.4, random_state=1111, weights = data['Weight'])\n",
    "data = stupid_dataset\n",
    "y = data['Creditability']\n",
    "data = data.drop(columns=['Purpose', 'Creditability', 'Weight',  'Payment Status of Previous Credit', 'Guarantors'])\n",
    "\n",
    "# y = data['Creditability']\n",
    "# data = data.drop(columns=['Purpose', 'Creditability', 'Payment Status of Previous Credit', 'Guarantors'])\n",
    "\n",
    "\n",
    "# The data contains some categorical variables which need to be one-hot-encoded\n",
    "categorical_vars = {'Credit Purpose': 3}\n",
    "#check whether I want to keep purpose variable like this or merge certain purposes, also something weird with number of levels\n",
    "purpose = {1:'Car', 2:'Home Related', 3:'Other'}\n",
    "sex_marital_status = {1:'Male+Divorced', 2:'Male+Single', 3:'Male+Married/Widowed', 4:'Female'}\n",
    "concurrent_credit = {1: 'Other Banks', 2:'Dept.Stores', 3:'None'}\n",
    "telephone = {1: 'Yes', 2: 'No'}\n",
    "foreign_worker = {1: 'Yes', 2: 'No'}\n",
    "\n",
    "\n",
    "data_one_hot_encoded = data.replace({\"Credit Purpose\": purpose})\n",
    "data_one_hot_encoded = pd.get_dummies(data_one_hot_encoded, columns=categorical_vars.keys())\n",
    "\n",
    "\n",
    "X = data_one_hot_encoded\n",
    "features = X.columns.values\n",
    "print(features)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one-hot- encoded data is splitted in a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "# The one-hot-encoded training data is further splitted into a validation- and training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train, X_val, X_test = X_train.values, X_val.values, X_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.2,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=3, min_child_weight=1, gamma = 0.2, missing = np.nan)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.52077209e-02  4.29019362e-01 -2.84021329e-02  7.04068065e-01\n",
      "  -4.31192398e-01  2.91840851e-01 -3.74038704e-02  2.34752335e-02\n",
      "   0.00000000e+00  1.05744880e-02]\n",
      " [-1.79828089e-02 -4.99776155e-01 -7.14113355e-01  3.64628732e-02\n",
      "  -1.55133054e-01  2.43428200e-01 -5.15499488e-02  7.21724257e-02\n",
      "   0.00000000e+00 -7.86137860e-03]\n",
      " [ 5.44339698e-03 -4.16906416e-01  3.61595362e-01 -3.98885041e-01\n",
      "  -4.63943243e-01  3.59641165e-01 -4.20507267e-02  5.43503575e-02\n",
      "   0.00000000e+00 -1.48123130e-03]\n",
      " [-1.62343979e-02  7.90923536e-01 -1.44427657e-01  5.25869727e-01\n",
      "   1.79433212e-01  2.57238388e-01 -5.16829528e-02 -5.90474950e-03\n",
      "   0.00000000e+00  1.23130409e-02]\n",
      " [ 2.28518294e-03 -8.34467933e-02  5.42844892e-01  5.28681517e-01\n",
      "  -3.46059874e-02  4.52760428e-01 -6.20385744e-02  2.01710984e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [-1.62343979e-02  6.56295598e-01 -1.18756361e-01  4.94234711e-01\n",
      "   6.87885210e-02  2.62910157e-01 -4.52951379e-02  2.44751759e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [-2.13974323e-02  2.43148297e-01  4.68458980e-02 -1.02660942e+00\n",
      "  -2.93683320e-01  1.51707023e-01 -1.97486356e-02 -5.43593653e-02\n",
      "   0.00000000e+00  1.06683439e-02]\n",
      " [ 5.44339698e-03 -5.01806557e-01 -2.60028094e-01 -3.56371939e-01\n",
      "   1.59570053e-01  2.97789156e-01 -3.24217742e-03 -1.20782778e-01\n",
      "   0.00000000e+00 -1.48123130e-03]\n",
      " [ 1.60989712e-03 -5.63790679e-01  5.38151562e-01  4.22007382e-01\n",
      "  -1.57778636e-01  4.73757625e-01 -6.63653910e-02  1.47170573e-02\n",
      "   0.00000000e+00 -2.59003136e-02]\n",
      " [ 5.44339698e-03 -4.09868360e-01 -1.33194700e-01  3.96778494e-01\n",
      "  -5.20277858e-01  2.99734890e-01 -2.88303196e-02  2.01710984e-02\n",
      "   0.00000000e+00 -1.48123130e-03]\n",
      " [ 9.50181764e-03  8.93618166e-01  4.58378643e-01  4.16981764e-02\n",
      "  -6.25581861e-01  1.68574318e-01 -3.49625647e-02  3.58767137e-02\n",
      "   0.00000000e+00  3.30877281e-03]\n",
      " [ 5.44339698e-03 -2.91089445e-01  5.07052660e-01  7.84684241e-01\n",
      "  -8.85384530e-02  5.03821731e-01 -5.05930632e-02  2.01710984e-02\n",
      "   0.00000000e+00 -1.48123130e-03]\n",
      " [ 5.44339698e-03 -2.70814508e-01  2.85786539e-01  4.31942105e-01\n",
      "  -6.13278039e-02  4.26326811e-01 -2.99649090e-02 -4.21215873e-03\n",
      "   0.00000000e+00  1.64017901e-02]\n",
      " [ 6.34360407e-03  5.87304458e-02  2.02885598e-01  5.27938008e-01\n",
      "   8.86557251e-02  3.12437773e-01 -5.86579405e-02 -4.21215873e-03\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [-1.44979488e-02 -6.86063051e-01 -1.90991342e-01 -3.41132253e-01\n",
      "  -1.56848490e-01 -8.28354537e-01 -4.17481884e-02  5.48594221e-02\n",
      "   0.00000000e+00  8.13841075e-02]\n",
      " [-1.52077209e-02  9.09340978e-01 -1.81278154e-01 -3.57393235e-01\n",
      "   3.03266823e-01  2.72322983e-01 -3.21514942e-02  6.52284026e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [-1.62343979e-02  7.85437226e-01 -1.86042503e-01  4.22175854e-01\n",
      "  -1.90791041e-01  2.54720449e-01 -3.17661762e-02 -4.70571592e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 5.66831790e-03  1.09126842e+00 -1.86571240e-01  3.11405867e-01\n",
      "   2.83873916e-01  2.20935211e-01 -3.09134983e-02 -4.05090861e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 9.50181764e-03  9.93278325e-01  7.10585952e-01 -1.87879965e-01\n",
      "  -2.49308541e-01  2.24126518e-01 -3.49625647e-02  3.58767137e-02\n",
      "   0.00000000e+00  3.30877281e-03]\n",
      " [-5.72430855e-03 -5.37659109e-01  1.75502837e-01  4.43932176e-01\n",
      "   4.97380942e-02  3.97130519e-01 -6.22929446e-02  2.01710984e-02\n",
      "   0.00000000e+00 -2.59003136e-02]\n",
      " [ 6.06948975e-03 -9.14171636e-01  1.06560796e-01 -7.23362803e-01\n",
      "  -7.51073211e-02 -9.86177921e-01 -6.51783347e-02 -1.20782778e-01\n",
      "   0.00000000e+00 -1.57246254e-02]\n",
      " [ 5.44339698e-03 -3.92416388e-01 -1.08302914e-01  4.71454561e-01\n",
      "  -6.25159638e-03  3.79719108e-01 -2.28846688e-02  2.07370743e-02\n",
      "   0.00000000e+00 -1.48123130e-03]\n",
      " [-5.99264912e-02 -3.02171111e-01 -1.10444009e+00 -1.91701621e-01\n",
      "  -6.59380332e-02  1.77115828e-01  1.92289054e-01 -3.72082070e-02\n",
      "   0.00000000e+00  5.87833859e-03]\n",
      " [-4.69762972e-03 -4.49735194e-01  2.50073344e-01  3.59559029e-01\n",
      "  -1.67168528e-01  3.97130519e-01 -5.62929288e-02  2.01710984e-02\n",
      "   0.00000000e+00 -2.59003136e-02]\n",
      " [ 6.26799650e-03 -3.53172302e-01 -9.56083238e-01  3.66427660e-01\n",
      "   1.12460054e-01  2.12614447e-01  4.04075086e-01  5.39821945e-03\n",
      "   0.00000000e+00  7.25469179e-03]\n",
      " [-1.52077209e-02  1.51291102e-01 -2.02115789e-01 -9.29165483e-01\n",
      "  -4.00363863e-01  2.73654222e-01 -3.65396626e-02  6.52284026e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [-2.13974323e-02 -4.98571843e-02  4.51721132e-01  1.16633451e+00\n",
      "   5.54067731e-01  2.84098357e-01 -3.66526917e-02  5.43503575e-02\n",
      "   0.00000000e+00  2.17287452e-03]\n",
      " [ 1.03264181e-02  1.00089125e-01 -6.12236500e-01  5.43243960e-02\n",
      "   1.52547866e-01  1.81101173e-01 -3.67899202e-02  1.15256347e-01\n",
      "   0.00000000e+00  7.25469179e-03]\n",
      " [ 5.44339698e-03 -3.32480818e-02  4.81662035e-01 -8.88432376e-03\n",
      "   4.15689051e-01  4.34771568e-01 -4.46474217e-02  5.96568733e-02\n",
      "   0.00000000e+00  9.19813570e-03]\n",
      " [ 9.50181764e-03  8.48570287e-01  1.82421386e-01 -4.96916212e-02\n",
      "   5.56656599e-01  1.68574318e-01 -3.49625647e-02  3.58767137e-02\n",
      "   0.00000000e+00  3.30877281e-03]\n",
      " [-1.11095168e-01  1.09026027e+00  2.63304055e-01  2.00661525e-01\n",
      "   2.83594906e-01 -4.11892205e-01 -2.35250276e-02  1.00768179e-01\n",
      "   0.00000000e+00  7.31821805e-02]\n",
      " [ 5.66831790e-03  1.08512378e+00 -1.54440299e-01  5.43904126e-01\n",
      "   2.74195671e-01  2.18770519e-01 -4.27672155e-02 -1.13587938e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 6.06948975e-03 -7.93075442e-01 -2.19024137e-01  2.31130794e-01\n",
      "   4.67711650e-02 -9.12462771e-01 -6.39493614e-02 -5.07952608e-02\n",
      "   0.00000000e+00 -1.57246254e-02]\n",
      " [-1.52077209e-02  3.84206384e-01 -9.28307027e-02  3.80306095e-01\n",
      "  -3.47638994e-01  2.62910157e-01 -4.44841012e-02  1.89875737e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 6.34360407e-03  8.50987017e-01  2.97535598e-01  3.66427273e-01\n",
      "  -1.46238983e-01  2.15406433e-01 -4.20934372e-02  3.58767137e-02\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 6.06948975e-03 -3.52163315e-01 -1.93132833e-01  3.65742803e-01\n",
      "  -3.41475792e-02 -8.92177522e-01 -6.38320819e-02  2.01710984e-02\n",
      "   0.00000000e+00  4.75299545e-03]\n",
      " [ 2.28518294e-03 -7.15688884e-01  4.48368996e-01 -2.02579880e+00\n",
      "  -1.45755574e-01  3.85043561e-01 -6.03509694e-02 -1.20782778e-01\n",
      "   0.00000000e+00 -2.59003136e-02]\n",
      " [ 3.47012356e-02 -3.25542748e-01 -6.56175375e-01  3.28286923e-02\n",
      "   2.98235059e-01  2.61824757e-01 -2.33013164e-02 -5.26667759e-02\n",
      "   0.00000000e+00  5.87833859e-03]\n",
      " [-1.52077209e-02  4.19475675e-01 -1.21201634e-01  4.55087334e-01\n",
      "  -4.06730294e-01  2.62910157e-01 -4.36198972e-02 -5.39568486e-03\n",
      "   0.00000000e+00 -1.04879160e-04]\n",
      " [ 9.50181764e-03  6.53703034e-01 -6.74955472e-02  1.48619160e-01\n",
      "  -2.78425008e-01  2.10085362e-01 -8.68374016e-03  2.97275409e-02\n",
      "   0.00000000e+00  3.30877281e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Here a shap explainer is made to explain the prediction for the test set\n",
    "shap_explainer = shap.TreeExplainer(model)\n",
    "shap_values_test = shap_explainer.shap_values(X_test)\n",
    "\n",
    "print(shap_values_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6431545451283455\n",
      "0.4883608128875494\n",
      "0.3124878199771047\n",
      "0.1647652474232018\n",
      "0.07394859744235874\n",
      "0.03852517502382398\n",
      "0.018854462902527302\n",
      "0.0053153777107581845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_shap(shaps):\n",
    "    return (shaps-min(shaps))/(max(shaps) - min(shaps))\n",
    "\n",
    "\n",
    "#transforms the probability of a prediction to confidence of prediction, by scaling number between 0 and 1\n",
    "def probability_to_confidence(prob):\n",
    "    return ((prob-0.5)/0.5)\n",
    "\n",
    "#maybe do this for \" most critical\", second most critical etc\n",
    "def calc_impact(theta, n):\n",
    "    number_of_impacts = 0\n",
    "    normalized_shap_values = []\n",
    "    for i in range(0, X_test.shape[0]):\n",
    "        test_pred = model.predict([X_test[i]])\n",
    "        test_prob = model.predict_proba([X_test[i]])[0]\n",
    "        test_prob_pred = test_prob[test_pred[0]]\n",
    "        confidence = probability_to_confidence(test_prob_pred)\n",
    "\n",
    "        #get top2 indeces out of absolute values \n",
    "        shaps = abs(shap_values_test[i])\n",
    "        normalized_shaps = norm_shap(shaps)\n",
    "        sorted_indices = np.argsort(shaps)\n",
    "        critical = sorted_indices[len(sorted_indices) - n]\n",
    "        new_x = X_test[i].copy()\n",
    "        new_x[critical] = np.nan\n",
    "        test_pred_new = model.predict([new_x])\n",
    "        test_prob_new = model.predict_proba([new_x])[0]\n",
    "        test_prob_pred_new = test_prob_new[test_pred_new[0]]\n",
    "        test_confidence_new = probability_to_confidence(test_prob_pred_new)\n",
    "        \n",
    "        number_of_impacts += ((test_pred_new != test_pred) or (test_confidence_new <= confidence*theta))\n",
    "        \n",
    "        normalized_shap_values.append(normalized_shaps[critical])\n",
    "    \n",
    "    print(str(sum(normalized_shap_values)/len(normalized_shap_values)))\n",
    "    return number_of_impacts/X_test.shape[0]\n",
    "\n",
    "calc_impact(0.5, 1)\n",
    "calc_impact(0.5, 2)\n",
    "calc_impact(0.5, 3)\n",
    "calc_impact(0.5, 4)\n",
    "calc_impact(0.5, 5)\n",
    "calc_impact(0.5, 6)\n",
    "calc_impact(0.5, 7)\n",
    "calc_impact(0.5, 8)\n",
    "calc_impact(0.5, 9)\n",
    "# for i in range(1, 10):\n",
    "#     print(calc_impact(0.5, i))\n",
    "\n",
    "# test_pred = model.predict(X_test)\n",
    "# test_prob = model.predict_proba(X_test)\n",
    "# true_class_label = y_test[i]\n",
    "# predicted_class_label = test_pred[i]\n",
    "\n",
    "# prob_predicted_class_label = test_prob[i]\n",
    "# print(prob_predicted_class_label[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
